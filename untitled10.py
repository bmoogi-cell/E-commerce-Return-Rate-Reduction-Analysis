# -*- coding: utf-8 -*-
"""Untitled10.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cUNmIVMj7wbbRsxzoEF1q4NggNdNv0dn
"""

# ----------------------------------------------------------
# ğŸ“¦ E-commerce Return Rate Reduction Analysis - Colab Code
# ----------------------------------------------------------

# Install required libraries
!pip install pandas numpy scikit-learn matplotlib seaborn

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.preprocessing import LabelEncoder

# --------------------------------------
# ğŸ“¥ STEP 1: Upload Data Files
# --------------------------------------
from google.colab import files

print("Upload your ORDER dataset (orders.csv)")
uploaded_orders = files.upload()

print("Upload your RETURNS dataset (returns.csv)")
uploaded_returns = files.upload()

orders = pd.read_csv(list(uploaded_orders.keys())[0])
returns = pd.read_csv(list(uploaded_returns.keys())[0])

print("Orders Shape:", orders.shape)
print("Returns Shape:", returns.shape)


# ---------------------------------------------------
# ğŸ§¹ STEP 2: Clean & Merge Datasets
# ---------------------------------------------------

# Standardize column names
orders.columns = orders.columns.str.lower()
returns.columns = returns.columns.str.lower()

# Ensure order_id column exists in both
if "order_id" not in orders.columns or "order_id" not in returns.columns:
    raise KeyError("âŒ Required column 'order_id' missing in one of the files.")

# Merge datasets
df = orders.merge(returns, on="order_id", how="left")

# Mark returned = 1, not returned = 0
df["is_returned"] = np.where(df["return_reason"].notna(), 1, 0)

print("Merged Data Shape:", df.shape)
df.head()


# ---------------------------------------------------
# ğŸ“Š STEP 3: Return Analysis by Category, Supplier, Geo
# ---------------------------------------------------

# Return % by category
return_by_cat = df.groupby("category")["is_returned"].mean().reset_index()
return_by_cat.rename(columns={"is_returned":"return_rate"}, inplace=True)
print("\nğŸ“Œ Return % by Category:")
print(return_by_cat)

# Return % by supplier
return_by_supplier = df.groupby("supplier")["is_returned"].mean().reset_index()
return_by_supplier.rename(columns={"is_returned":"return_rate"}, inplace=True)

# Return % by geography (if available)
geo_cols = ["state", "city", "region"]
for col in geo_cols:
    if col in df.columns:
        print(f"\nğŸ“Œ Return % by {col.capitalize()}")
        display(df.groupby(col)["is_returned"].mean().reset_index())


# ---------------------------------------------------
# ğŸ¨ STEP 4: Visualization
# ---------------------------------------------------

plt.figure(figsize=(10,6))
sns.barplot(data=return_by_cat, x="category", y="return_rate")
plt.xticks(rotation=45)
plt.title("Return % by Category")
plt.show()


# ---------------------------------------------------
# ğŸ¤– STEP 5: Logistic Regression Model
# ---------------------------------------------------

# Select features (update based on your dataset!)
features = ["price", "quantity", "category", "supplier"]

# Keep only existing columns
features = [f for f in features if f in df.columns]

model_df = df[features + ["is_returned"]].dropna()

# Encode categorical columns
le = LabelEncoder()
for col in model_df.columns:
    if model_df[col].dtype == "object":
        model_df[col] = le.fit_transform(model_df[col])

X = model_df.drop("is_returned", axis=1)
y = model_df["is_returned"]

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train model
logreg = LogisticRegression(max_iter=200)
logreg.fit(X_train, y_train)

# Evaluate
pred = logreg.predict(X_test)
print("\nğŸ“Œ Classification Report:")
print(classification_report(y_test, pred))

print("\nğŸ“Œ Confusion Matrix:")
print(confusion_matrix(y_test, pred))


# ---------------------------------------------------
# ğŸ” STEP 6: Predict Return Probability for All Products
# ---------------------------------------------------

df_model_ready = df[features].copy()

# Encode same way
for col in df_model_ready.columns:
    if df_model_ready[col].dtype == "object":
        df_model_ready[col] = le.fit_transform(df_model_ready[col].astype(str))

df["return_probability"] = logreg.predict_proba(df_model_ready)[:,1]

# Products with >40% return probability
high_risk = df[df["return_probability"] > 0.40]

high_risk.to_csv("high_risk_products.csv", index=False)

print("\nğŸ“ High-risk products saved as: high_risk_products.csv")

files.download("high_risk_products.csv")